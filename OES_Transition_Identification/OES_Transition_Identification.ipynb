{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OES_Transition_Identification\n",
    "\n",
    "Written by: Ketong Shao and Angelo D. Bonzanini\n",
    "\n",
    "Date: October 2021\n",
    "\n",
    "* Reduce the OES spectra dimension using the trained Autoencoder\n",
    "* Hyperparamter determination of Random forest using Bayesian optimization and 5-fold cross validation\n",
    "* Examine the prediction accuracies using confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Mount Google Drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained Autoencoder and reduce the OES data dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OES spectrum are first normalized by deviding their largest peaks.\n",
    "# Therefore, each spectra has the highest intensity value as 1.\n",
    "spec_regen = np.genfromtxt('corrp_specs0.001.csv',delimiter=',')\n",
    "trans_id = np.genfromtxt('OES_true_labels.csv',delimiter=',')\n",
    "# Load the traiend autoencider\n",
    "autoencoder = tf.keras.models.load_model('autoencoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_auto: (1620, 10)\n",
      "-----------------------------------------------\n",
      "X_test_auto: (1620, 10)\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test dataset, which are the same as in the previous .ipynb script.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(spec_regen, trans_id, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build the scaler for OES data. Sometimes, 'StandardScaler' could be a good choice.\n",
    "# It is not necessary and reasonable to normalize the output labels, which are just 1s or 0s.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_OES = MinMaxScaler()\n",
    "scaled_Xtrain = scaler_OES.fit_transform(X_train)\n",
    "scaled_Xtest = scaler_OES.transform(X_test)\n",
    "\n",
    "# Compress the OES spectra data\n",
    "X_train_auto = autoencoder.encoder(scaled_Xtrain)\n",
    "Y_train_auto = y_train\n",
    "\n",
    "X_test_auto = autoencoder.encoder(scaled_Xtest)\n",
    "Y_test_auto = y_test\n",
    "\n",
    "# Print the shape of compressed OES\n",
    "print('X_train_auto:', X_train_auto.shape)\n",
    "print('-----------------------------------------------')\n",
    "print('X_test_auto:', X_train_auto.shape)\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest hyperparameters selection by 5-fold cross-validation and Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (from scikit-optimize) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (from scikit-optimize) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (from scikit-optimize) (0.17.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\n",
      "Requirement already satisfied: PyYAML in /Users/shaoketong/anaconda3/lib/python3.8/site-packages (from pyaml>=16.9->scikit-optimize) (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Necessary packages installation and importing\n",
    "! pip install scikit-optimize\n",
    "import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer \n",
    "\n",
    "import sklearn.model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyparameters of Random forest to be tuned\n",
    "dim_feature = Integer(low=1, high=10, prior='log-uniform',name='feature')\n",
    "dim_number = Integer(low=50,high=10000, prior='uniform',name='number')\n",
    "dim_depth = Integer(low=1, high=60, prior='log-uniform',name='depth')\n",
    "\n",
    "dimensions = [dim_feature,\n",
    "              dim_number,\n",
    "              dim_depth]\n",
    "# initial value, from which the Bayesian optimization starts\n",
    "default_parameters = [2,60,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective to be minimized by Bayesian Optimization.\n",
    "# Here, the objective is the accuracy of prediction. \n",
    "# For example, if the true lable is (1,1,1), i.e all the three transitions exist, while the prediction is (1,0,1),\n",
    "# then this prediction will be treated as FALSE.\n",
    "# The accuracy is the percentage of TRUE.\n",
    "\n",
    "# Here 5-fold cross-validation is integrated into the objective function, \n",
    "# making the found hyperparameters more general and accurate.\n",
    "# 5-fold cross-validation is extremely useful when the data is small.\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def random_multi_acc(feature,number,depth):\n",
    "    splits_n = 5\n",
    "\n",
    "    kf = sklearn.model_selection.KFold(n_splits=splits_n,random_state=42, shuffle=True)\n",
    "    kf.get_n_splits(X_train_auto)\n",
    "    \n",
    "    score = 0\n",
    "    for train_index, test_index in kf.split(X_train_auto):\n",
    "\n",
    "            RF = RandomForestClassifier(n_estimators=number,max_features=feature,max_depth=depth).fit(X_train_auto[train_index,:], \n",
    "                                                  Y_train_auto[train_index,:])\n",
    "            score += RF.score(X_train_auto[test_index,:], Y_train_auto[test_index,:])\n",
    "    print(score/5)\n",
    "    return -score/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CheckpointSaver to save the optimization process in case of any interruption \n",
    "# This Bayesian optimization might take some time.\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "\n",
    "checkpoint_saver = CheckpointSaver(\"./checkpoint.pkl\", compress=9) # keyword arguments will be passed to `skopt.dump`\n",
    "\n",
    "# last_res = skopt.load('checkpoint.pkl')\n",
    "\n",
    "gp_result = gp_minimize(func=random_multi_acc,\n",
    "                            dimensions=dimensions,\n",
    "                            n_calls=400,\n",
    "                            noise= 1e-8,\n",
    "                            n_jobs=-1,\n",
    "                            acq_func=\"EI\",\n",
    "                            x0=default_parameters,\n",
    "                            #if starting from last checkpoint, comment out x0 = default_parameters,\n",
    "                            #add x = last_res.x_iters, y = last_res.func_vals\n",
    "                            callback=[checkpoint_saver],\n",
    "                       )\n",
    "opt_h = gp_result.x[0],gp_result.x[1],gp_result.x[2]\n",
    "print(opt_h)\n",
    "print(gp_result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the finished Bayesian optimization\n",
    "# skopt.dump(gp_result,'BO_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestf found accuracy: 0.6876543209876542\n",
      "-----------------------------------------------\n",
      "Hyperparameter values: [7, 5854, 32]\n",
      "-----------------------------------------------\n",
      "Corresponding to: \n",
      " Features at each decision tree node: 7 \n",
      " Number of decision trees in the Random forest: 5854 \n",
      " Maximal depth of each decision tree: 32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we directly load the completed Bayesian Optimization, with 400 evaluations.\n",
    "# Note, you may obtain different hyperparameter values, but the score should be close.\n",
    "BO_result = skopt.load('BO_result')\n",
    "\n",
    "# Print the found best accuracy\n",
    "print('Bestf found accuracy:', -BO_result.fun)\n",
    "print('-----------------------------------------------')\n",
    "# Print the corresponding hyperparameter values\n",
    "print('Hyperparameter values:', BO_result.x)\n",
    "print('-----------------------------------------------')\n",
    "print('Corresponding to:','\\n',\n",
    "      'Features at each decision tree node:', BO_result.x[0],'\\n',\n",
    "      'Number of decision trees in the Random forest:', BO_result.x[1],'\\n',\n",
    "      'Maximal depth of each decision tree:', BO_result.x[2],'\\n',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the predition accuracy for each transition using the never-seen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the confusion_matrix, which tells the numbers of true positive, false position, false negative and true negative.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Train the Random forest using all the training data set with the found hyperparameters\n",
    "RSs = RandomForestClassifier(n_estimators=5854,max_features=7,max_depth=32).fit(X_train_auto, Y_train_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSs.score(X_train_auto[test_index,:], Y_train_auto[test_index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For N2(1+) :\n",
      "TN: 45 FP: 17 FN: 9 TP: 109\n",
      "For N2(2+) :\n",
      "TN: 54 FP: 18 FN: 4 TP: 104\n",
      "For NO Gamma :\n",
      "TN: 46 FP: 8 FN: 8 TP: 118\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix for each transition using the never-seen test set\n",
    "transition_name = ['N2(1+)', 'N2(2+)', 'NO Gamma']\n",
    "for _ in range(3):\n",
    "    c_tn, c_fp, c_fn, c_tp = confusion_matrix(RSs.predict(X_test_auto)[:,_],\n",
    "                                              Y_test_auto[:,_]).ravel()\n",
    "    print('For', transition_name[_], ':')\n",
    "    print('TN:',c_tn,'FP:', c_fp,'FN:', c_fn,'TP:', c_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall, the accuracy for each transition is high.\n",
    "# It is noticeable that the accuracies of N2(1+) and N2(2+) are lower than that of NO Gamma.\n",
    "# The reason is that in some OES simulations, the concentration of NO is unusually high.\n",
    "# While the NO Gamma transition is extremely strong, making the transitions of N2(1+) and N2(2+) unrecognisable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
